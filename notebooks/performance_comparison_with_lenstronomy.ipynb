{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing jaxtronomy and lenstronomy performance for lens model ray shooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaxtronomy execution time for CONVERGENCE: 0.12926510000033886 seconds\n",
      "lenstronomy execution time for CONVERGENCE: 0.24261440000009316 seconds\n",
      "jaxtronomy is 1.9x faster\n",
      "\n",
      "jaxtronomy execution time for CSE: 0.1693755999986024 seconds\n",
      "lenstronomy execution time for CSE: 0.8399465000002238 seconds\n",
      "jaxtronomy is 5.0x faster\n",
      "\n",
      "jaxtronomy execution time for EPL: 7.1486386000015045 seconds\n",
      "lenstronomy execution time for EPL: 83.05072649999966 seconds\n",
      "jaxtronomy is 11.6x faster\n",
      "\n",
      "jaxtronomy execution time for EPL: 7.1486386000015045 seconds\n",
      "lenstronomy execution time for EPL_NUMBA: 8.942944800000987 seconds\n",
      "jaxtronomy is 1.3x faster\n",
      "\n",
      "jaxtronomy execution time for EPL_Q_PHI: 6.708962799999426 seconds\n",
      "lenstronomy execution time for EPL_Q_PHI: 2.124331400000301 seconds\n",
      "jaxtronomy is 0.3x faster\n",
      "\n",
      "jaxtronomy execution time for GAUSSIAN: 0.29490329999862297 seconds\n",
      "lenstronomy execution time for GAUSSIAN: 0.6275099000013142 seconds\n",
      "jaxtronomy is 2.1x faster\n",
      "\n",
      "jaxtronomy execution time for GAUSSIAN_POTENTIAL: 0.2947110999994038 seconds\n",
      "lenstronomy execution time for GAUSSIAN_POTENTIAL: 0.5804102000001876 seconds\n",
      "jaxtronomy is 2.0x faster\n",
      "\n",
      "jaxtronomy execution time for HERNQUIST: 0.5752646999990247 seconds\n",
      "lenstronomy execution time for HERNQUIST: 1.2580627000006643 seconds\n",
      "jaxtronomy is 2.2x faster\n",
      "\n",
      "jaxtronomy execution time for HERNQUIST_ELLIPSE_CSE: 4.105937000000267 seconds\n",
      "lenstronomy execution time for HERNQUIST_ELLIPSE_CSE: 20.95274740000059 seconds\n",
      "jaxtronomy is 5.1x faster\n",
      "\n",
      "jaxtronomy execution time for LOS: 0.2007731000012427 seconds\n",
      "lenstronomy execution time for LOS: 0.5669726999985869 seconds\n",
      "jaxtronomy is 2.8x faster\n",
      "\n",
      "jaxtronomy execution time for LOS_MINIMAL: 0.1989685999997164 seconds\n",
      "lenstronomy execution time for LOS_MINIMAL: 0.5519533000006049 seconds\n",
      "jaxtronomy is 2.8x faster\n",
      "\n",
      "jaxtronomy execution time for NFW: 0.581805699999677 seconds\n",
      "lenstronomy execution time for NFW: 1.2622533000012481 seconds\n",
      "jaxtronomy is 2.2x faster\n",
      "\n",
      "jaxtronomy execution time for NFW_ELLIPSE_CSE: 4.5349685000001045 seconds\n",
      "lenstronomy execution time for NFW_ELLIPSE_CSE: 23.315340499999365 seconds\n",
      "jaxtronomy is 5.1x faster\n",
      "\n",
      "jaxtronomy execution time for NIE: 0.7469242000006489 seconds\n",
      "lenstronomy execution time for NIE: 0.9014362999987497 seconds\n",
      "jaxtronomy is 1.2x faster\n",
      "\n",
      "jaxtronomy execution time for PJAFFE: 0.3715305999994598 seconds\n",
      "lenstronomy execution time for PJAFFE: 0.6210934000009729 seconds\n",
      "jaxtronomy is 1.7x faster\n",
      "\n",
      "jaxtronomy execution time for PJAFFE_ELLIPSE_POTENTIAL: 0.40805809999983467 seconds\n",
      "lenstronomy execution time for PJAFFE_ELLIPSE_POTENTIAL: 1.054672500000379 seconds\n",
      "jaxtronomy is 2.6x faster\n",
      "\n",
      "jaxtronomy execution time for SHEAR: 0.1405718000005436 seconds\n",
      "lenstronomy execution time for SHEAR: 0.2947506999989855 seconds\n",
      "jaxtronomy is 2.1x faster\n",
      "\n",
      "jaxtronomy execution time for SIE: 0.8198943999996118 seconds\n",
      "lenstronomy execution time for SIE: 0.9232603999989806 seconds\n",
      "jaxtronomy is 1.1x faster\n",
      "\n",
      "jaxtronomy execution time for SIS: 0.11661970000022848 seconds\n",
      "lenstronomy execution time for SIS: 0.379754799998409 seconds\n",
      "jaxtronomy is 3.3x faster\n",
      "\n",
      "jaxtronomy execution time for SPP: 0.550740599999699 seconds\n",
      "lenstronomy execution time for SPP: 0.7365515999990748 seconds\n",
      "jaxtronomy is 1.3x faster\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from jax import numpy as jnp, config\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from jaxtronomy.LensModel.lens_model import LensModel\n",
    "from lenstronomy.LensModel.lens_model import LensModel as LensModel_ref\n",
    "from jaxtronomy.LensModel.profile_list_base import (\n",
    "    _JAXXED_MODELS as JAXXED_DEFLECTOR_PROFILES,\n",
    ")\n",
    "\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "\n",
    "# 60x60 grid\n",
    "num_pix = 60\n",
    "supersampling_factor = 3\n",
    "supersampling = False\n",
    "\n",
    "if supersampling:\n",
    "    num_pix *= supersampling_factor\n",
    "\n",
    "x_jax = jnp.tile(jnp.linspace(-5.0, 5.0, num_pix) + 100, num_pix)\n",
    "y_jax = jnp.repeat(jnp.linspace(-5.0, 5.0, num_pix) + 100, num_pix)\n",
    "\n",
    "x = np.tile(np.linspace(-5.0, 5.0, num_pix) + 100, num_pix)\n",
    "y = np.repeat(np.linspace(-5.0, 5.0, num_pix) + 100, num_pix)\n",
    "\n",
    "for deflector_profile in JAXXED_DEFLECTOR_PROFILES:\n",
    "    lensModel_ref = LensModel_ref([deflector_profile])\n",
    "    lensModel = LensModel([deflector_profile])\n",
    "\n",
    "    # Get parameter names\n",
    "    kwargs_lens = lensModel.lens_model.func_list[0].upper_limit_default\n",
    "\n",
    "    # Compile code/warmup\n",
    "    result = lensModel.ray_shooting(x_jax, y_jax, [kwargs_lens])\n",
    "    result_ref = lensModel_ref.ray_shooting(x, y, [kwargs_lens])\n",
    "    np.testing.assert_allclose(result, result_ref, rtol=1e-3, atol=1e-3)\n",
    "\n",
    "    # Now time runtime after compilation/warmup\n",
    "    start_time = time.perf_counter()\n",
    "    for _ in range(10000):\n",
    "        lensModel.ray_shooting(x_jax, y_jax, [kwargs_lens])\n",
    "\n",
    "    middle_time = time.perf_counter()\n",
    "\n",
    "    for _ in range(10000):\n",
    "        lensModel_ref.ray_shooting(x, y, [kwargs_lens])\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    jax_execution_time = middle_time - start_time\n",
    "    lenstronomy_execution_time = end_time - middle_time\n",
    "    print(\n",
    "        f\"jaxtronomy execution time for {deflector_profile}: {jax_execution_time} seconds\"\n",
    "    )\n",
    "    print(\n",
    "        f\"lenstronomy execution time for {deflector_profile}: {lenstronomy_execution_time} seconds\"\n",
    "    )\n",
    "    print(\n",
    "        f\"jaxtronomy is {'{0:.1f}'.format(lenstronomy_execution_time/jax_execution_time)}x faster\\n\"\n",
    "    )\n",
    "\n",
    "    # Additional performance comparison with EPL_NUMBA\n",
    "    if deflector_profile == \"EPL\":\n",
    "        lensModel_epl_numba = LensModel_ref([\"EPL_NUMBA\"])\n",
    "        lensModel_epl_numba.ray_shooting(x, y, [kwargs_lens])\n",
    "        start_time = time.perf_counter()\n",
    "        for _ in range(10000):\n",
    "            lensModel_epl_numba.ray_shooting(x, y, [kwargs_lens])\n",
    "        end_time = time.perf_counter()\n",
    "        numba_execution_time = end_time - start_time\n",
    "\n",
    "        print(f\"jaxtronomy execution time for EPL: {jax_execution_time} seconds\")\n",
    "        print(\n",
    "            f\"lenstronomy execution time for EPL_NUMBA: {numba_execution_time} seconds\"\n",
    "        )\n",
    "        print(\n",
    "            f\"jaxtronomy is {'{0:.1f}'.format(numba_execution_time/jax_execution_time)}x faster\\n\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing jaxtronomy and lenstronomy performance for light model surface brightness\n",
    "Note: Restarting the kernel is recommended before running the below tests on a low-memory machine, otherwise you may introduce a memory bottleneck from caching all of the compiled functions from the lens model testing in the previous cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaxtronomy execution time for CORE_SERSIC: 0.45475860000078683 seconds\n",
      "lenstronomy execution time for CORE_SERSIC: 2.4216302999993786 seconds\n",
      "jaxtronomy is 5.3x faster\n",
      "\n",
      "jaxtronomy execution time for GAUSSIAN: 0.1258683000014571 seconds\n",
      "lenstronomy execution time for GAUSSIAN: 0.3730510999994294 seconds\n",
      "jaxtronomy is 3.0x faster\n",
      "\n",
      "jaxtronomy execution time for GAUSSIAN_ELLIPSE: 0.20272420000037528 seconds\n",
      "lenstronomy execution time for GAUSSIAN_ELLIPSE: 0.5507977000015671 seconds\n",
      "jaxtronomy is 2.7x faster\n",
      "\n",
      "jaxtronomy execution time for MULTI_GAUSSIAN: 0.21117310000045109 seconds\n",
      "lenstronomy execution time for MULTI_GAUSSIAN: 1.6327565999999933 seconds\n",
      "jaxtronomy is 7.7x faster\n",
      "\n",
      "jaxtronomy execution time for MULTI_GAUSSIAN_ELLIPSE: 0.25613220000013825 seconds\n",
      "lenstronomy execution time for MULTI_GAUSSIAN_ELLIPSE: 1.936380300001474 seconds\n",
      "jaxtronomy is 7.6x faster\n",
      "\n",
      "jaxtronomy execution time for SERSIC: 0.3276308999993489 seconds\n",
      "lenstronomy execution time for SERSIC: 1.2243885999996564 seconds\n",
      "jaxtronomy is 3.7x faster\n",
      "\n",
      "jaxtronomy execution time for SERSIC_ELLIPSE: 0.3286800999994739 seconds\n",
      "lenstronomy execution time for SERSIC_ELLIPSE: 1.1623813999976846 seconds\n",
      "jaxtronomy is 3.5x faster\n",
      "\n",
      "jaxtronomy execution time for SERSIC_ELLIPSE_Q_PHI: 0.32461809999949764 seconds\n",
      "lenstronomy execution time for SERSIC_ELLIPSE_Q_PHI: 1.1966996999981347 seconds\n",
      "jaxtronomy is 3.7x faster\n",
      "\n",
      "jaxtronomy execution time for SHAPELETS: 1.423691099997086 seconds\n",
      "lenstronomy execution time for SHAPELETS: 14.32395870000255 seconds\n",
      "jaxtronomy is 10.1x faster\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from jax import numpy as jnp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from jaxtronomy.LightModel.light_model import LightModel\n",
    "from lenstronomy.LightModel.light_model import LightModel as LightModel_ref\n",
    "from jaxtronomy.LightModel.light_model_base import (\n",
    "    _JAXXED_MODELS as JAXXED_SOURCE_PROFILES,\n",
    ")\n",
    "\n",
    "# 60x60 grid\n",
    "num_pix = 60\n",
    "supersampling_factor = 3\n",
    "supersampling = False\n",
    "\n",
    "if supersampling:\n",
    "    num_pix *= supersampling_factor\n",
    "\n",
    "x_jax = jnp.tile(jnp.linspace(-5.0, 5.0, num_pix) + 100, num_pix)\n",
    "y_jax = jnp.repeat(jnp.linspace(-5.0, 5.0, num_pix) + 100, num_pix)\n",
    "\n",
    "x = np.tile(np.linspace(-5.0, 5.0, num_pix) + 100, num_pix)\n",
    "y = np.repeat(np.linspace(-5.0, 5.0, num_pix) + 100, num_pix)\n",
    "\n",
    "for source_profile in JAXXED_SOURCE_PROFILES:\n",
    "    lightModel = LightModel([source_profile])\n",
    "    lightModel_ref = LightModel_ref([source_profile])\n",
    "    kwargs_source = copy.deepcopy(lightModel.func_list[0].upper_limit_default)\n",
    "    if source_profile in [\"MULTI_GAUSSIAN\", \"MULTI_GAUSSIAN_ELLIPSE\"]:\n",
    "        kwargs_source[\"amp\"] = np.linspace(10, 20, 5)\n",
    "        kwargs_source[\"sigma\"] = np.linspace(0.3, 1.0, 5)\n",
    "    elif source_profile == \"SHAPELETS\":\n",
    "        n_max = 10\n",
    "        num_param = int((n_max + 1) * (n_max + 2) / 2)\n",
    "        kwargs_source[\"n_max\"] = n_max\n",
    "        kwargs_source[\"amp\"] = np.linspace(20.0, 30.0, num_param)\n",
    "\n",
    "    # Compile code/warmup\n",
    "    lightModel.surface_brightness(x_jax, y_jax, [kwargs_source])\n",
    "    lightModel_ref.surface_brightness(x, y, [kwargs_source])\n",
    "\n",
    "    # Now time runtime after compilation/warmup\n",
    "    start_time = time.perf_counter()\n",
    "    for _ in range(10000):\n",
    "        lightModel.surface_brightness(x_jax, y_jax, [kwargs_source])\n",
    "\n",
    "    middle_time = time.perf_counter()\n",
    "\n",
    "    for _ in range(10000):\n",
    "        lightModel_ref.surface_brightness(x, y, [kwargs_source])\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    jax_execution_time = middle_time - start_time\n",
    "    lenstronomy_execution_time = end_time - middle_time\n",
    "    print(\n",
    "        f\"jaxtronomy execution time for {source_profile}: {jax_execution_time} seconds\"\n",
    "    )\n",
    "    print(\n",
    "        f\"lenstronomy execution time for {source_profile}: {lenstronomy_execution_time} seconds\"\n",
    "    )\n",
    "    print(\n",
    "        f\"jaxtronomy is {'{0:.1f}'.format(lenstronomy_execution_time/jax_execution_time)}x faster\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing jaxtronomy and lenstronomy performance for image convolution\n",
    "We start by comparing Gaussian convolution. Due to the fact that there is no jax.scipy.ndimage.gaussian_filter function, in jaxtronomy we implement gaussian convolution by constructing a gaussian kernel and performing a pixel kernel fft convolution. This is done in such a way to match scipy.ndimage.guassian_filter with mode=\"nearest\" as closely as possible. The jaxtronomy implementation is slower, but the benefit of this JAX implementation is that we can use autodifferentiation for model fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaxtronomy execution time for gaussian convolution with kernel radius 5: 0.6235142000004998 seconds\n",
      "lenstronomy execution time for gaussian convolution with kernel radius 5: 0.4927905999975337 seconds\n",
      "lenstronomy is 1.3x faster\n",
      "\n",
      "jaxtronomy execution time for gaussian convolution with kernel radius 9: 0.7403319999975793 seconds\n",
      "lenstronomy execution time for gaussian convolution with kernel radius 9: 0.5890407000006235 seconds\n",
      "lenstronomy is 1.3x faster\n",
      "\n",
      "jaxtronomy execution time for gaussian convolution with kernel radius 14: 2.004389199999423 seconds\n",
      "lenstronomy execution time for gaussian convolution with kernel radius 14: 0.7015000000028522 seconds\n",
      "lenstronomy is 2.9x faster\n",
      "\n",
      "jaxtronomy execution time for gaussian convolution with kernel radius 18: 1.489607800001977 seconds\n",
      "lenstronomy execution time for gaussian convolution with kernel radius 18: 0.7453275999978359 seconds\n",
      "lenstronomy is 2.0x faster\n",
      "\n",
      "jaxtronomy execution time for gaussian convolution with kernel radius 23: 2.4005331000007573 seconds\n",
      "lenstronomy execution time for gaussian convolution with kernel radius 23: 1.1412792000010086 seconds\n",
      "lenstronomy is 2.1x faster\n",
      "\n",
      "jaxtronomy execution time for gaussian convolution with kernel radius 27: 2.344429000000673 seconds\n",
      "lenstronomy execution time for gaussian convolution with kernel radius 27: 1.5645566999992297 seconds\n",
      "lenstronomy is 1.5x faster\n",
      "\n",
      "jaxtronomy execution time for gaussian convolution with kernel radius 32: 5.495426500001486 seconds\n",
      "lenstronomy execution time for gaussian convolution with kernel radius 32: 1.8100851999988663 seconds\n",
      "lenstronomy is 3.0x faster\n",
      "\n",
      "jaxtronomy execution time for gaussian convolution with kernel radius 36: 4.296770799999649 seconds\n",
      "lenstronomy execution time for gaussian convolution with kernel radius 36: 1.8652107000016258 seconds\n",
      "lenstronomy is 2.3x faster\n",
      "\n",
      "jaxtronomy execution time for gaussian convolution with kernel radius 41: 4.0077443000009225 seconds\n",
      "lenstronomy execution time for gaussian convolution with kernel radius 41: 1.9779290000005858 seconds\n",
      "lenstronomy is 2.0x faster\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lenstronomy.ImSim.Numerics.convolution import MultiGaussianConvolution\n",
    "from jaxtronomy.ImSim.Numerics.convolution import GaussianConvolution\n",
    "\n",
    "from jax import numpy as jnp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "num_pix = 60\n",
    "sigma = 0.5\n",
    "pixel_scale = 0.11\n",
    "supersampling_factor = 3\n",
    "supersampling_convolution = False\n",
    "\n",
    "for truncation in range(1, 10):\n",
    "\n",
    "    jax_conv = GaussianConvolution(\n",
    "        sigma, pixel_scale, supersampling_factor, supersampling_convolution, truncation\n",
    "    )\n",
    "    lenstronomy_conv = MultiGaussianConvolution(\n",
    "        [sigma],\n",
    "        [1],\n",
    "        pixel_scale,\n",
    "        supersampling_factor,\n",
    "        supersampling_convolution,\n",
    "        truncation,\n",
    "    )\n",
    "\n",
    "    kernel_radius = round(sigma * truncation / pixel_scale)\n",
    "    if supersampling_convolution:\n",
    "        kernel_radius *= supersampling_factor\n",
    "\n",
    "    image_jax = jnp.tile(jnp.linspace(1.0, 100.0, num_pix), num_pix).reshape(\n",
    "        (num_pix, num_pix)\n",
    "    )\n",
    "    image = np.tile(np.linspace(1.0, 100.0, num_pix), num_pix).reshape(\n",
    "        (num_pix, num_pix)\n",
    "    )\n",
    "\n",
    "    # Compile code/warmup\n",
    "    result_jax = jax_conv.convolution2d(image_jax)\n",
    "    result = lenstronomy_conv.convolution2d(image)\n",
    "    np.testing.assert_allclose(result_jax, result, rtol=1e-5, atol=1e-5)\n",
    "\n",
    "    # Now time runtime after compilation/warmup\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    for _ in range(10000):\n",
    "        jax_conv.convolution2d(image_jax)\n",
    "\n",
    "    middle_time = time.perf_counter()\n",
    "\n",
    "    for _ in range(10000):\n",
    "        lenstronomy_conv.convolution2d(image)\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    jax_execution_time = middle_time - start_time\n",
    "    lenstronomy_execution_time = end_time - middle_time\n",
    "    print(\n",
    "        f\"jaxtronomy execution time for gaussian convolution with kernel radius {kernel_radius}: {jax_execution_time} seconds\"\n",
    "    )\n",
    "    print(\n",
    "        f\"lenstronomy execution time for gaussian convolution with kernel radius {kernel_radius}: {lenstronomy_execution_time} seconds\"\n",
    "    )\n",
    "    print(\n",
    "        f\"lenstronomy is {'{0:.1f}'.format(jax_execution_time/lenstronomy_execution_time)}x faster\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compare fft convolution with a given kernel. Generally, jax.scipy.signal.fftconvolve is about twice as fast as the normal scipy version, but there are some specific kernel sizes where the jax version is slower than usual for some unknown reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaxtronomy execution time for fft convolution with kernel size 3: 0.7521321000021999 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 3: 0.932906499998353 seconds\n",
      "jaxtronomy is 1.2x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 5: 0.44844689999808907 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 5: 0.9823906000019633 seconds\n",
      "jaxtronomy is 2.2x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 7: 0.5849750000015774 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 7: 1.0667126000007556 seconds\n",
      "jaxtronomy is 1.8x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 9: 0.6611798000012641 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 9: 0.9508036999977776 seconds\n",
      "jaxtronomy is 1.4x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 11: 0.6411372000002302 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 11: 1.122929600001953 seconds\n",
      "jaxtronomy is 1.8x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 13: 0.4906981000021915 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 13: 0.9090813999973761 seconds\n",
      "jaxtronomy is 1.9x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 15: 1.0003537999982655 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 15: 1.0041559999990568 seconds\n",
      "jaxtronomy is 1.0x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 17: 0.732698400002846 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 17: 1.0327062999967893 seconds\n",
      "jaxtronomy is 1.4x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 19: 0.6870385000001988 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 19: 1.011649899999611 seconds\n",
      "jaxtronomy is 1.5x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 21: 0.5412177999969572 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 21: 1.005398100001912 seconds\n",
      "jaxtronomy is 1.9x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 23: 1.2739228999998886 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 23: 1.1852323999992223 seconds\n",
      "jaxtronomy is 0.9x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 25: 0.6769015999998373 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 25: 1.1826631000003545 seconds\n",
      "jaxtronomy is 1.7x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 27: 1.3358636000011757 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 27: 1.189254199998686 seconds\n",
      "jaxtronomy is 0.9x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 29: 0.7061581999987538 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 29: 1.1930533000013384 seconds\n",
      "jaxtronomy is 1.7x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 31: 0.7023176000002422 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 31: 1.188166399999318 seconds\n",
      "jaxtronomy is 1.7x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 33: 1.0275577000029443 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 33: 1.2403280999969866 seconds\n",
      "jaxtronomy is 1.2x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 35: 1.6387771999980032 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 35: 1.270222900002409 seconds\n",
      "jaxtronomy is 0.8x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 37: 0.7058938999980455 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 37: 1.2729995000008785 seconds\n",
      "jaxtronomy is 1.8x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 39: 0.9510031999998318 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 39: 1.4385911999997916 seconds\n",
      "jaxtronomy is 1.5x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 41: 0.7695614000003843 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 41: 1.4517830999975558 seconds\n",
      "jaxtronomy is 1.9x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 43: 1.0789258000004338 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 43: 1.6012317999993684 seconds\n",
      "jaxtronomy is 1.5x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 45: 1.0324863999994704 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 45: 1.6769855999991705 seconds\n",
      "jaxtronomy is 1.6x faster\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lenstronomy.ImSim.Numerics.convolution import (\n",
    "    PixelKernelConvolution as PixelKernelConvolution_ref,\n",
    ")\n",
    "from jaxtronomy.ImSim.Numerics.convolution import PixelKernelConvolution\n",
    "\n",
    "from jax import numpy as jnp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "num_pix = 60\n",
    "kernel_size_list = np.linspace(3, 45, 22, dtype=int)\n",
    "\n",
    "supersampling_factor = 3\n",
    "supersampling_convolution = False\n",
    "\n",
    "if supersampling_convolution:\n",
    "    num_pix *= supersampling_factor\n",
    "    kernel_size_list *= supersampling_factor\n",
    "\n",
    "for kernel_size in kernel_size_list:\n",
    "    kernel_jax = jnp.tile(jnp.linspace(0.1, 1.0, kernel_size), kernel_size).reshape(\n",
    "        (kernel_size, kernel_size)\n",
    "    )\n",
    "    kernel_jax = kernel_jax / jnp.sum(kernel_jax)\n",
    "    kernel = np.tile(np.linspace(0.1, 1.0, kernel_size), kernel_size).reshape(\n",
    "        (kernel_size, kernel_size)\n",
    "    )\n",
    "    kernel = kernel / np.sum(kernel)\n",
    "\n",
    "    jax_conv = PixelKernelConvolution(kernel=kernel_jax, convolution_type=\"fft\")\n",
    "    lenstronomy_conv = PixelKernelConvolution_ref(kernel=kernel, convolution_type=\"fft\")\n",
    "\n",
    "    image_jax = jnp.tile(jnp.linspace(1.0, 20.0, num_pix), num_pix).reshape(\n",
    "        (num_pix, num_pix)\n",
    "    )\n",
    "    image = np.tile(np.linspace(1.0, 20.0, num_pix), num_pix).reshape(\n",
    "        (num_pix, num_pix)\n",
    "    )\n",
    "\n",
    "    # Compile code/warmup\n",
    "    result_jax = jax_conv.convolution2d(image_jax)\n",
    "    result = lenstronomy_conv.convolution2d(image)\n",
    "    np.testing.assert_allclose(result_jax, result, rtol=1e-5, atol=1e-5)\n",
    "\n",
    "    # Now time runtime after compilation/warmup\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    for _ in range(10000):\n",
    "        jax_conv.convolution2d(image_jax)\n",
    "\n",
    "    middle_time = time.perf_counter()\n",
    "\n",
    "    for _ in range(10000):\n",
    "        lenstronomy_conv.convolution2d(image)\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    jax_execution_time = middle_time - start_time\n",
    "    lenstronomy_execution_time = end_time - middle_time\n",
    "    print(\n",
    "        f\"jaxtronomy execution time for fft convolution with kernel size {kernel_size}: {jax_execution_time} seconds\"\n",
    "    )\n",
    "    print(\n",
    "        f\"lenstronomy execution time for fft convolution with kernel size {kernel_size}: {lenstronomy_execution_time} seconds\"\n",
    "    )\n",
    "    print(\n",
    "        f\"jaxtronomy is {'{0:.1f}'.format(lenstronomy_execution_time/jax_execution_time)}x faster\\n\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
