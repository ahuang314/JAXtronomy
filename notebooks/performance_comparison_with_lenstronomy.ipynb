{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing jaxtronomy and lenstronomy performance for lens model ray shooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaxtronomy execution time for CONVERGENCE: 0.4313851000042632 seconds\n",
      "lenstronomy execution time for CONVERGENCE: 0.36154939999687485 seconds\n",
      "jaxtronomy is 0.8x faster\n",
      "\n",
      "jaxtronomy execution time for CSE: 1.4031409999952302 seconds\n",
      "lenstronomy execution time for CSE: 4.426417300004687 seconds\n",
      "jaxtronomy is 3.2x faster\n",
      "\n",
      "jaxtronomy execution time for EPL: 53.55844120000256 seconds\n",
      "lenstronomy execution time for EPL: 748.1092546 seconds\n",
      "jaxtronomy is 14.0x faster\n",
      "\n",
      "jaxtronomy execution time for EPL: 53.55844120000256 seconds\n",
      "lenstronomy execution time for EPL_NUMBA: 93.39384889999928 seconds\n",
      "jaxtronomy is 1.7x faster\n",
      "\n",
      "jaxtronomy execution time for EPL_Q_PHI: 53.811627100003534 seconds\n",
      "lenstronomy execution time for EPL_Q_PHI: 15.962233400001423 seconds\n",
      "jaxtronomy is 0.3x faster\n",
      "\n",
      "jaxtronomy execution time for GAUSSIAN: 1.919069399998989 seconds\n",
      "lenstronomy execution time for GAUSSIAN: 3.553127499995753 seconds\n",
      "jaxtronomy is 1.9x faster\n",
      "\n",
      "jaxtronomy execution time for GAUSSIAN_POTENTIAL: 2.0029972000047565 seconds\n",
      "lenstronomy execution time for GAUSSIAN_POTENTIAL: 3.541295600000012 seconds\n",
      "jaxtronomy is 1.8x faster\n",
      "\n",
      "jaxtronomy execution time for HERNQUIST: 2.6690623000031337 seconds\n",
      "lenstronomy execution time for HERNQUIST: 11.527385200002755 seconds\n",
      "jaxtronomy is 4.3x faster\n",
      "\n",
      "jaxtronomy execution time for HERNQUIST_ELLIPSE_CSE: 31.644719500000065 seconds\n",
      "lenstronomy execution time for HERNQUIST_ELLIPSE_CSE: 136.20759259999613 seconds\n",
      "jaxtronomy is 4.3x faster\n",
      "\n",
      "jaxtronomy execution time for NFW: 2.44573759999912 seconds\n",
      "lenstronomy execution time for NFW: 7.746452499995939 seconds\n",
      "jaxtronomy is 3.2x faster\n",
      "\n",
      "jaxtronomy execution time for NFW_ELLIPSE_CSE: 31.708836300000257 seconds\n",
      "lenstronomy execution time for NFW_ELLIPSE_CSE: 165.0642200000002 seconds\n",
      "jaxtronomy is 5.2x faster\n",
      "\n",
      "jaxtronomy execution time for NIE: 4.805869300005725 seconds\n",
      "lenstronomy execution time for NIE: 7.688041399997019 seconds\n",
      "jaxtronomy is 1.6x faster\n",
      "\n",
      "jaxtronomy execution time for PJAFFE: 4.524332300003152 seconds\n",
      "lenstronomy execution time for PJAFFE: 3.7697793999977876 seconds\n",
      "jaxtronomy is 0.8x faster\n",
      "\n",
      "jaxtronomy execution time for PJAFFE_ELLIPSE_POTENTIAL: 4.6526505000001634 seconds\n",
      "lenstronomy execution time for PJAFFE_ELLIPSE_POTENTIAL: 7.579550900001777 seconds\n",
      "jaxtronomy is 1.6x faster\n",
      "\n",
      "jaxtronomy execution time for SHEAR: 0.6542012999998406 seconds\n",
      "lenstronomy execution time for SHEAR: 1.0608337000012398 seconds\n",
      "jaxtronomy is 1.6x faster\n",
      "\n",
      "jaxtronomy execution time for SIE: 5.655415399996855 seconds\n",
      "lenstronomy execution time for SIE: 6.638286600005813 seconds\n",
      "jaxtronomy is 1.2x faster\n",
      "\n",
      "jaxtronomy execution time for SIS: 1.052994999998191 seconds\n",
      "lenstronomy execution time for SIS: 1.7649461000037263 seconds\n",
      "jaxtronomy is 1.7x faster\n",
      "\n",
      "jaxtronomy execution time for SPP: 3.115124600000854 seconds\n",
      "lenstronomy execution time for SPP: 5.4434899000043515 seconds\n",
      "jaxtronomy is 1.7x faster\n",
      "\n",
      "jaxtronomy execution time for TNFW: 3.9383853000035742 seconds\n",
      "lenstronomy execution time for TNFW: 15.5345484999998 seconds\n",
      "jaxtronomy is 3.9x faster\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from jax import numpy as jnp, config, block_until_ready\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from jaxtronomy.LensModel.profile_list_base import lens_class, _JAXXED_MODELS as JAXXED_DEFLECTOR_PROFILES\n",
    "from lenstronomy.LensModel.profile_list_base import lens_class as lens_class_lenstronomy\n",
    "\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "num_pix = 180\n",
    "\n",
    "x_jax = jnp.tile(jnp.linspace(-5.0, 5.0, num_pix) + 100, num_pix)\n",
    "y_jax = jnp.repeat(jnp.linspace(-5.0, 5.0, num_pix) + 100, num_pix)\n",
    "\n",
    "x = np.tile(np.linspace(-5.0, 5.0, num_pix) + 100, num_pix)\n",
    "y = np.repeat(np.linspace(-5.0, 5.0, num_pix) + 100, num_pix)\n",
    "\n",
    "for deflector_profile in JAXXED_DEFLECTOR_PROFILES:\n",
    "    # Skip these profiles\n",
    "    if deflector_profile in [\"LOS\", \"LOS_MINIMAL\"]:\n",
    "        continue\n",
    "\n",
    "    profile_lenstronomy = lens_class_lenstronomy(deflector_profile)\n",
    "    profile = lens_class(deflector_profile)\n",
    "\n",
    "    # Get parameter names\n",
    "    kwargs_lens = profile.upper_limit_default\n",
    "\n",
    "    # Compile code/warmup\n",
    "    f_x, f_y = profile_lenstronomy.derivatives(x, y, **kwargs_lens)\n",
    "    f_x, f_y = profile.derivatives(x_jax, y_jax, **kwargs_lens)\n",
    "    block_until_ready(f_x)\n",
    "    block_until_ready(f_y)\n",
    "    \n",
    "\n",
    "    # Now time runtime after compilation/warmup\n",
    "    start_time = time.perf_counter()\n",
    "    for _ in range(10000):\n",
    "        f_x, f_y = profile.derivatives(x_jax, y_jax, **kwargs_lens)\n",
    "        block_until_ready(f_x)\n",
    "        block_until_ready(f_y)\n",
    "\n",
    "    middle_time = time.perf_counter()\n",
    "\n",
    "    for _ in range(10000):\n",
    "        f_x, f_y = profile_lenstronomy.derivatives(x, y, **kwargs_lens)\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    jax_execution_time = middle_time - start_time\n",
    "    lenstronomy_execution_time = end_time - middle_time\n",
    "    print(\n",
    "        f\"jaxtronomy execution time for {deflector_profile}: {jax_execution_time} seconds\"\n",
    "    )\n",
    "    print(\n",
    "        f\"lenstronomy execution time for {deflector_profile}: {lenstronomy_execution_time} seconds\"\n",
    "    )\n",
    "    print(\n",
    "        f\"jaxtronomy is {'{0:.1f}'.format(lenstronomy_execution_time/jax_execution_time)}x faster\\n\"\n",
    "    )\n",
    "\n",
    "    # Additional performance comparison with EPL_NUMBA\n",
    "    if deflector_profile == \"EPL\":\n",
    "        profile_lenstronomy = lens_class_lenstronomy(\"EPL_NUMBA\")\n",
    "        f_x, f_y = profile_lenstronomy.derivatives(x, y, **kwargs_lens)\n",
    "        start_time = time.perf_counter()\n",
    "        for _ in range(10000):\n",
    "            f_x, f_y = profile_lenstronomy.derivatives(x, y, **kwargs_lens)\n",
    "        end_time = time.perf_counter()\n",
    "        numba_execution_time = end_time - start_time\n",
    "\n",
    "        print(f\"jaxtronomy execution time for EPL: {jax_execution_time} seconds\")\n",
    "        print(\n",
    "            f\"lenstronomy execution time for EPL_NUMBA: {numba_execution_time} seconds\"\n",
    "        )\n",
    "        print(\n",
    "            f\"jaxtronomy is {'{0:.1f}'.format(numba_execution_time/jax_execution_time)}x faster\\n\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing jaxtronomy and lenstronomy performance for light model surface brightness\n",
    "Note: Restarting the kernel is recommended before running the below tests on a low-memory machine, otherwise you may introduce a memory bottleneck from caching all of the compiled functions from the lens model testing in the previous cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaxtronomy execution time for CORE_SERSIC: 0.45475860000078683 seconds\n",
      "lenstronomy execution time for CORE_SERSIC: 2.4216302999993786 seconds\n",
      "jaxtronomy is 5.3x faster\n",
      "\n",
      "jaxtronomy execution time for GAUSSIAN: 0.1258683000014571 seconds\n",
      "lenstronomy execution time for GAUSSIAN: 0.3730510999994294 seconds\n",
      "jaxtronomy is 3.0x faster\n",
      "\n",
      "jaxtronomy execution time for GAUSSIAN_ELLIPSE: 0.20272420000037528 seconds\n",
      "lenstronomy execution time for GAUSSIAN_ELLIPSE: 0.5507977000015671 seconds\n",
      "jaxtronomy is 2.7x faster\n",
      "\n",
      "jaxtronomy execution time for MULTI_GAUSSIAN: 0.21117310000045109 seconds\n",
      "lenstronomy execution time for MULTI_GAUSSIAN: 1.6327565999999933 seconds\n",
      "jaxtronomy is 7.7x faster\n",
      "\n",
      "jaxtronomy execution time for MULTI_GAUSSIAN_ELLIPSE: 0.25613220000013825 seconds\n",
      "lenstronomy execution time for MULTI_GAUSSIAN_ELLIPSE: 1.936380300001474 seconds\n",
      "jaxtronomy is 7.6x faster\n",
      "\n",
      "jaxtronomy execution time for SERSIC: 0.3276308999993489 seconds\n",
      "lenstronomy execution time for SERSIC: 1.2243885999996564 seconds\n",
      "jaxtronomy is 3.7x faster\n",
      "\n",
      "jaxtronomy execution time for SERSIC_ELLIPSE: 0.3286800999994739 seconds\n",
      "lenstronomy execution time for SERSIC_ELLIPSE: 1.1623813999976846 seconds\n",
      "jaxtronomy is 3.5x faster\n",
      "\n",
      "jaxtronomy execution time for SERSIC_ELLIPSE_Q_PHI: 0.32461809999949764 seconds\n",
      "lenstronomy execution time for SERSIC_ELLIPSE_Q_PHI: 1.1966996999981347 seconds\n",
      "jaxtronomy is 3.7x faster\n",
      "\n",
      "jaxtronomy execution time for SHAPELETS: 1.423691099997086 seconds\n",
      "lenstronomy execution time for SHAPELETS: 14.32395870000255 seconds\n",
      "jaxtronomy is 10.1x faster\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from jax import numpy as jnp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from jaxtronomy.LightModel.light_model import LightModel\n",
    "from lenstronomy.LightModel.light_model import LightModel as LightModel_ref\n",
    "from jaxtronomy.LightModel.light_model_base import (\n",
    "    _JAXXED_MODELS as JAXXED_SOURCE_PROFILES,\n",
    ")\n",
    "\n",
    "# 60x60 grid\n",
    "num_pix = 60\n",
    "\n",
    "x_jax = jnp.tile(jnp.linspace(-5.0, 5.0, num_pix) + 100, num_pix)\n",
    "y_jax = jnp.repeat(jnp.linspace(-5.0, 5.0, num_pix) + 100, num_pix)\n",
    "\n",
    "x = np.tile(np.linspace(-5.0, 5.0, num_pix) + 100, num_pix)\n",
    "y = np.repeat(np.linspace(-5.0, 5.0, num_pix) + 100, num_pix)\n",
    "\n",
    "for source_profile in JAXXED_SOURCE_PROFILES:\n",
    "    lightModel = LightModel([source_profile])\n",
    "    lightModel_ref = LightModel_ref([source_profile])\n",
    "    kwargs_source = copy.deepcopy(lightModel.func_list[0].upper_limit_default)\n",
    "    if source_profile in [\"MULTI_GAUSSIAN\", \"MULTI_GAUSSIAN_ELLIPSE\"]:\n",
    "        kwargs_source[\"amp\"] = np.linspace(10, 20, 5)\n",
    "        kwargs_source[\"sigma\"] = np.linspace(0.3, 1.0, 5)\n",
    "    elif source_profile == \"SHAPELETS\":\n",
    "        n_max = 10\n",
    "        num_param = int((n_max + 1) * (n_max + 2) / 2)\n",
    "        kwargs_source[\"n_max\"] = n_max\n",
    "        kwargs_source[\"amp\"] = np.linspace(20.0, 30.0, num_param)\n",
    "\n",
    "    # Compile code/warmup\n",
    "    lightModel.surface_brightness(x_jax, y_jax, [kwargs_source])\n",
    "    lightModel_ref.surface_brightness(x, y, [kwargs_source])\n",
    "\n",
    "    # Now time runtime after compilation/warmup\n",
    "    start_time = time.perf_counter()\n",
    "    for _ in range(10000):\n",
    "        lightModel.surface_brightness(x_jax, y_jax, [kwargs_source])\n",
    "\n",
    "    middle_time = time.perf_counter()\n",
    "\n",
    "    for _ in range(10000):\n",
    "        lightModel_ref.surface_brightness(x, y, [kwargs_source])\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    jax_execution_time = middle_time - start_time\n",
    "    lenstronomy_execution_time = end_time - middle_time\n",
    "    print(\n",
    "        f\"jaxtronomy execution time for {source_profile}: {jax_execution_time} seconds\"\n",
    "    )\n",
    "    print(\n",
    "        f\"lenstronomy execution time for {source_profile}: {lenstronomy_execution_time} seconds\"\n",
    "    )\n",
    "    print(\n",
    "        f\"jaxtronomy is {'{0:.1f}'.format(lenstronomy_execution_time/jax_execution_time)}x faster\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing jaxtronomy and lenstronomy performance for image convolution\n",
    "We start by comparing Gaussian convolution. Due to the fact that there is no jax.scipy.ndimage.gaussian_filter function, in jaxtronomy we implement gaussian convolution by constructing a gaussian kernel and performing a pixel kernel fft convolution. This is done in such a way to match scipy.ndimage.guassian_filter with mode=\"nearest\" as closely as possible. The jaxtronomy implementation is slower, but the benefit of this JAX implementation is that we can use autodifferentiation for model fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaxtronomy execution time for gaussian convolution with kernel radius 5: 0.6235142000004998 seconds\n",
      "lenstronomy execution time for gaussian convolution with kernel radius 5: 0.4927905999975337 seconds\n",
      "lenstronomy is 1.3x faster\n",
      "\n",
      "jaxtronomy execution time for gaussian convolution with kernel radius 9: 0.7403319999975793 seconds\n",
      "lenstronomy execution time for gaussian convolution with kernel radius 9: 0.5890407000006235 seconds\n",
      "lenstronomy is 1.3x faster\n",
      "\n",
      "jaxtronomy execution time for gaussian convolution with kernel radius 14: 2.004389199999423 seconds\n",
      "lenstronomy execution time for gaussian convolution with kernel radius 14: 0.7015000000028522 seconds\n",
      "lenstronomy is 2.9x faster\n",
      "\n",
      "jaxtronomy execution time for gaussian convolution with kernel radius 18: 1.489607800001977 seconds\n",
      "lenstronomy execution time for gaussian convolution with kernel radius 18: 0.7453275999978359 seconds\n",
      "lenstronomy is 2.0x faster\n",
      "\n",
      "jaxtronomy execution time for gaussian convolution with kernel radius 23: 2.4005331000007573 seconds\n",
      "lenstronomy execution time for gaussian convolution with kernel radius 23: 1.1412792000010086 seconds\n",
      "lenstronomy is 2.1x faster\n",
      "\n",
      "jaxtronomy execution time for gaussian convolution with kernel radius 27: 2.344429000000673 seconds\n",
      "lenstronomy execution time for gaussian convolution with kernel radius 27: 1.5645566999992297 seconds\n",
      "lenstronomy is 1.5x faster\n",
      "\n",
      "jaxtronomy execution time for gaussian convolution with kernel radius 32: 5.495426500001486 seconds\n",
      "lenstronomy execution time for gaussian convolution with kernel radius 32: 1.8100851999988663 seconds\n",
      "lenstronomy is 3.0x faster\n",
      "\n",
      "jaxtronomy execution time for gaussian convolution with kernel radius 36: 4.296770799999649 seconds\n",
      "lenstronomy execution time for gaussian convolution with kernel radius 36: 1.8652107000016258 seconds\n",
      "lenstronomy is 2.3x faster\n",
      "\n",
      "jaxtronomy execution time for gaussian convolution with kernel radius 41: 4.0077443000009225 seconds\n",
      "lenstronomy execution time for gaussian convolution with kernel radius 41: 1.9779290000005858 seconds\n",
      "lenstronomy is 2.0x faster\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lenstronomy.ImSim.Numerics.convolution import MultiGaussianConvolution\n",
    "from jaxtronomy.ImSim.Numerics.convolution import GaussianConvolution\n",
    "\n",
    "from jax import numpy as jnp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "num_pix = 60\n",
    "sigma = 0.5\n",
    "pixel_scale = 0.11\n",
    "supersampling_factor = 3\n",
    "supersampling_convolution = False\n",
    "\n",
    "for truncation in range(1, 10):\n",
    "\n",
    "    jax_conv = GaussianConvolution(\n",
    "        sigma, pixel_scale, supersampling_factor, supersampling_convolution, truncation\n",
    "    )\n",
    "    lenstronomy_conv = MultiGaussianConvolution(\n",
    "        [sigma],\n",
    "        [1],\n",
    "        pixel_scale,\n",
    "        supersampling_factor,\n",
    "        supersampling_convolution,\n",
    "        truncation,\n",
    "    )\n",
    "\n",
    "    kernel_radius = round(sigma * truncation / pixel_scale)\n",
    "    if supersampling_convolution:\n",
    "        kernel_radius *= supersampling_factor\n",
    "\n",
    "    image_jax = jnp.tile(jnp.linspace(1.0, 100.0, num_pix), num_pix).reshape(\n",
    "        (num_pix, num_pix)\n",
    "    )\n",
    "    image = np.tile(np.linspace(1.0, 100.0, num_pix), num_pix).reshape(\n",
    "        (num_pix, num_pix)\n",
    "    )\n",
    "\n",
    "    # Compile code/warmup\n",
    "    result_jax = jax_conv.convolution2d(image_jax)\n",
    "    result = lenstronomy_conv.convolution2d(image)\n",
    "    np.testing.assert_allclose(result_jax, result, rtol=1e-5, atol=1e-5)\n",
    "\n",
    "    # Now time runtime after compilation/warmup\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    for _ in range(10000):\n",
    "        jax_conv.convolution2d(image_jax)\n",
    "\n",
    "    middle_time = time.perf_counter()\n",
    "\n",
    "    for _ in range(10000):\n",
    "        lenstronomy_conv.convolution2d(image)\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    jax_execution_time = middle_time - start_time\n",
    "    lenstronomy_execution_time = end_time - middle_time\n",
    "    print(\n",
    "        f\"jaxtronomy execution time for gaussian convolution with kernel radius {kernel_radius}: {jax_execution_time} seconds\"\n",
    "    )\n",
    "    print(\n",
    "        f\"lenstronomy execution time for gaussian convolution with kernel radius {kernel_radius}: {lenstronomy_execution_time} seconds\"\n",
    "    )\n",
    "    print(\n",
    "        f\"lenstronomy is {'{0:.1f}'.format(jax_execution_time/lenstronomy_execution_time)}x faster\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compare fft convolution with a given kernel. Generally, jax.scipy.signal.fftconvolve is about twice as fast as the normal scipy version, but there are some specific kernel sizes where the jax version is slower than usual for some unknown reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaxtronomy execution time for fft convolution with kernel size 3: 0.7521321000021999 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 3: 0.932906499998353 seconds\n",
      "jaxtronomy is 1.2x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 5: 0.44844689999808907 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 5: 0.9823906000019633 seconds\n",
      "jaxtronomy is 2.2x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 7: 0.5849750000015774 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 7: 1.0667126000007556 seconds\n",
      "jaxtronomy is 1.8x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 9: 0.6611798000012641 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 9: 0.9508036999977776 seconds\n",
      "jaxtronomy is 1.4x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 11: 0.6411372000002302 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 11: 1.122929600001953 seconds\n",
      "jaxtronomy is 1.8x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 13: 0.4906981000021915 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 13: 0.9090813999973761 seconds\n",
      "jaxtronomy is 1.9x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 15: 1.0003537999982655 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 15: 1.0041559999990568 seconds\n",
      "jaxtronomy is 1.0x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 17: 0.732698400002846 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 17: 1.0327062999967893 seconds\n",
      "jaxtronomy is 1.4x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 19: 0.6870385000001988 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 19: 1.011649899999611 seconds\n",
      "jaxtronomy is 1.5x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 21: 0.5412177999969572 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 21: 1.005398100001912 seconds\n",
      "jaxtronomy is 1.9x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 23: 1.2739228999998886 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 23: 1.1852323999992223 seconds\n",
      "jaxtronomy is 0.9x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 25: 0.6769015999998373 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 25: 1.1826631000003545 seconds\n",
      "jaxtronomy is 1.7x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 27: 1.3358636000011757 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 27: 1.189254199998686 seconds\n",
      "jaxtronomy is 0.9x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 29: 0.7061581999987538 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 29: 1.1930533000013384 seconds\n",
      "jaxtronomy is 1.7x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 31: 0.7023176000002422 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 31: 1.188166399999318 seconds\n",
      "jaxtronomy is 1.7x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 33: 1.0275577000029443 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 33: 1.2403280999969866 seconds\n",
      "jaxtronomy is 1.2x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 35: 1.6387771999980032 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 35: 1.270222900002409 seconds\n",
      "jaxtronomy is 0.8x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 37: 0.7058938999980455 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 37: 1.2729995000008785 seconds\n",
      "jaxtronomy is 1.8x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 39: 0.9510031999998318 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 39: 1.4385911999997916 seconds\n",
      "jaxtronomy is 1.5x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 41: 0.7695614000003843 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 41: 1.4517830999975558 seconds\n",
      "jaxtronomy is 1.9x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 43: 1.0789258000004338 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 43: 1.6012317999993684 seconds\n",
      "jaxtronomy is 1.5x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 45: 1.0324863999994704 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 45: 1.6769855999991705 seconds\n",
      "jaxtronomy is 1.6x faster\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lenstronomy.ImSim.Numerics.convolution import (\n",
    "    PixelKernelConvolution as PixelKernelConvolution_ref,\n",
    ")\n",
    "from jaxtronomy.ImSim.Numerics.convolution import PixelKernelConvolution\n",
    "\n",
    "from jax import numpy as jnp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "num_pix = 60\n",
    "kernel_size_list = np.linspace(3, 45, 22, dtype=int)\n",
    "\n",
    "supersampling_factor = 3\n",
    "supersampling_convolution = False\n",
    "\n",
    "if supersampling_convolution:\n",
    "    num_pix *= supersampling_factor\n",
    "    kernel_size_list *= supersampling_factor\n",
    "\n",
    "for kernel_size in kernel_size_list:\n",
    "    kernel_jax = jnp.tile(jnp.linspace(0.1, 1.0, kernel_size), kernel_size).reshape(\n",
    "        (kernel_size, kernel_size)\n",
    "    )\n",
    "    kernel_jax = kernel_jax / jnp.sum(kernel_jax)\n",
    "    kernel = np.tile(np.linspace(0.1, 1.0, kernel_size), kernel_size).reshape(\n",
    "        (kernel_size, kernel_size)\n",
    "    )\n",
    "    kernel = kernel / np.sum(kernel)\n",
    "\n",
    "    jax_conv = PixelKernelConvolution(kernel=kernel_jax, convolution_type=\"fft\")\n",
    "    lenstronomy_conv = PixelKernelConvolution_ref(kernel=kernel, convolution_type=\"fft\")\n",
    "\n",
    "    image_jax = jnp.tile(jnp.linspace(1.0, 20.0, num_pix), num_pix).reshape(\n",
    "        (num_pix, num_pix)\n",
    "    )\n",
    "    image = np.tile(np.linspace(1.0, 20.0, num_pix), num_pix).reshape(\n",
    "        (num_pix, num_pix)\n",
    "    )\n",
    "\n",
    "    # Compile code/warmup\n",
    "    result_jax = jax_conv.convolution2d(image_jax)\n",
    "    result = lenstronomy_conv.convolution2d(image)\n",
    "    np.testing.assert_allclose(result_jax, result, rtol=1e-5, atol=1e-5)\n",
    "\n",
    "    # Now time runtime after compilation/warmup\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    for _ in range(10000):\n",
    "        jax_conv.convolution2d(image_jax)\n",
    "\n",
    "    middle_time = time.perf_counter()\n",
    "\n",
    "    for _ in range(10000):\n",
    "        lenstronomy_conv.convolution2d(image)\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    jax_execution_time = middle_time - start_time\n",
    "    lenstronomy_execution_time = end_time - middle_time\n",
    "    print(\n",
    "        f\"jaxtronomy execution time for fft convolution with kernel size {kernel_size}: {jax_execution_time} seconds\"\n",
    "    )\n",
    "    print(\n",
    "        f\"lenstronomy execution time for fft convolution with kernel size {kernel_size}: {lenstronomy_execution_time} seconds\"\n",
    "    )\n",
    "    print(\n",
    "        f\"jaxtronomy is {'{0:.1f}'.format(lenstronomy_execution_time/jax_execution_time)}x faster\\n\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
