{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing jaxtronomy and lenstronomy performance for lens model ray shooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaxtronomy execution time for CONVERGENCE: 0.20506839999870863 seconds\n",
      "lenstronomy execution time for CONVERGENCE: 1.4116154000003007 seconds\n",
      "jaxtronomy is 6.9x faster\n",
      "\n",
      "jaxtronomy execution time for CSE: 0.8139273999986472 seconds\n",
      "lenstronomy execution time for CSE: 8.218596400000024 seconds\n",
      "jaxtronomy is 10.1x faster\n",
      "\n",
      "jaxtronomy execution time for EPL: 37.05310129999998 seconds\n",
      "lenstronomy execution time for EPL_NUMBA: 80.56953299999986 seconds\n",
      "jaxtronomy is 2.2x faster\n",
      "\n",
      "jaxtronomy execution time for EPL_Q_PHI: 37.68870070000048 seconds\n",
      "lenstronomy execution time for EPL_Q_PHI: 16.48123719999967 seconds\n",
      "jaxtronomy is 0.4x faster\n",
      "\n",
      "jaxtronomy execution time for GAUSSIAN: 1.3453974000003655 seconds\n",
      "lenstronomy execution time for GAUSSIAN: 4.445075600000564 seconds\n",
      "jaxtronomy is 3.3x faster\n",
      "\n",
      "jaxtronomy execution time for GAUSSIAN_POTENTIAL: 1.3102717000001576 seconds\n",
      "lenstronomy execution time for GAUSSIAN_POTENTIAL: 4.051776199999949 seconds\n",
      "jaxtronomy is 3.1x faster\n",
      "\n",
      "jaxtronomy execution time for HERNQUIST: 3.0226738000001205 seconds\n",
      "lenstronomy execution time for HERNQUIST: 8.040270900000905 seconds\n",
      "jaxtronomy is 2.7x faster\n",
      "\n",
      "jaxtronomy execution time for HERNQUIST_ELLIPSE_CSE: 21.37112640000123 seconds\n",
      "lenstronomy execution time for HERNQUIST_ELLIPSE_CSE: 126.39906729999893 seconds\n",
      "jaxtronomy is 5.9x faster\n",
      "\n",
      "jaxtronomy execution time for LOS: 0.4149144000002707 seconds\n",
      "lenstronomy execution time for LOS: 3.1367479000000458 seconds\n",
      "jaxtronomy is 7.6x faster\n",
      "\n",
      "jaxtronomy execution time for LOS_MINIMAL: 0.3617054000005737 seconds\n",
      "lenstronomy execution time for LOS_MINIMAL: 2.9309061000003567 seconds\n",
      "jaxtronomy is 8.1x faster\n",
      "\n",
      "jaxtronomy execution time for NFW: 2.055050900000424 seconds\n",
      "lenstronomy execution time for NFW: 8.307823299999654 seconds\n",
      "jaxtronomy is 4.0x faster\n",
      "\n",
      "jaxtronomy execution time for NFW_ELLIPSE_CSE: 22.5045812999997 seconds\n",
      "lenstronomy execution time for NFW_ELLIPSE_CSE: 157.25661129999935 seconds\n",
      "jaxtronomy is 7.0x faster\n",
      "\n",
      "jaxtronomy execution time for NIE: 3.5572709999996732 seconds\n",
      "lenstronomy execution time for NIE: 6.885032100000899 seconds\n",
      "jaxtronomy is 1.9x faster\n",
      "\n",
      "jaxtronomy execution time for PJAFFE: 1.777666699999827 seconds\n",
      "lenstronomy execution time for PJAFFE: 4.289289400001508 seconds\n",
      "jaxtronomy is 2.4x faster\n",
      "\n",
      "jaxtronomy execution time for PJAFFE_ELLIPSE_POTENTIAL: 2.0047477000007348 seconds\n",
      "lenstronomy execution time for PJAFFE_ELLIPSE_POTENTIAL: 6.213596899999175 seconds\n",
      "jaxtronomy is 3.1x faster\n",
      "\n",
      "jaxtronomy execution time for SHEAR: 0.3599137000001065 seconds\n",
      "lenstronomy execution time for SHEAR: 1.9182888999985153 seconds\n",
      "jaxtronomy is 5.3x faster\n",
      "\n",
      "jaxtronomy execution time for SIE: 3.5042778000006365 seconds\n",
      "lenstronomy execution time for SIE: 6.575107900000148 seconds\n",
      "jaxtronomy is 1.9x faster\n",
      "\n",
      "jaxtronomy execution time for SIS: 0.6293553999985306 seconds\n",
      "lenstronomy execution time for SIS: 2.709951800001363 seconds\n",
      "jaxtronomy is 4.3x faster\n",
      "\n",
      "jaxtronomy execution time for SPP: 2.647850599998492 seconds\n",
      "lenstronomy execution time for SPP: 6.212179000000106 seconds\n",
      "jaxtronomy is 2.3x faster\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from jax import numpy as jnp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from jaxtronomy.LensModel.lens_model import LensModel\n",
    "from lenstronomy.LensModel.lens_model import LensModel as LensModel_ref\n",
    "from jaxtronomy.LensModel.profile_list_base import (\n",
    "    _JAXXED_MODELS as JAXXED_DEFLECTOR_PROFILES,\n",
    ")\n",
    "\n",
    "# 60x60 grid\n",
    "num_pix = 60\n",
    "supersampling_factor = 3\n",
    "supersampling = True\n",
    "\n",
    "if supersampling:\n",
    "    num_pix *= supersampling_factor\n",
    "\n",
    "x_jax = jnp.tile(jnp.linspace(-5.0, 5.0, num_pix) + 100, num_pix)\n",
    "y_jax = jnp.repeat(jnp.linspace(-5.0, 5.0, num_pix) + 100, num_pix)\n",
    "\n",
    "x = np.tile(np.linspace(-5.0, 5.0, num_pix) + 100, num_pix)\n",
    "y = np.repeat(np.linspace(-5.0, 5.0, num_pix) + 100, num_pix)\n",
    "\n",
    "for deflector_profile in JAXXED_DEFLECTOR_PROFILES:\n",
    "    lensModel = LensModel([deflector_profile])\n",
    "\n",
    "    if deflector_profile == \"EPL\":\n",
    "        lensModel_ref = LensModel_ref([\"EPL_NUMBA\"])\n",
    "    else:\n",
    "        lensModel_ref = LensModel_ref([deflector_profile])\n",
    "\n",
    "    kwargs_lens = lensModel.lens_model.func_list[0].upper_limit_default\n",
    "\n",
    "    # Compile code/warmup\n",
    "    lensModel.ray_shooting(x_jax, y_jax, [kwargs_lens])\n",
    "    lensModel_ref.ray_shooting(x, y, [kwargs_lens])\n",
    "\n",
    "    # Now time runtime after compilation/warmup\n",
    "    start_time = time.perf_counter()\n",
    "    for _ in range(10000):\n",
    "        lensModel.ray_shooting(x_jax, y_jax, [kwargs_lens])\n",
    "\n",
    "    middle_time = time.perf_counter()\n",
    "\n",
    "    for _ in range(10000):\n",
    "        lensModel_ref.ray_shooting(x, y, [kwargs_lens])\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    jax_execution_time = middle_time - start_time\n",
    "    lenstronomy_execution_time = end_time - middle_time\n",
    "    print(\n",
    "        f\"jaxtronomy execution time for {deflector_profile}: {jax_execution_time} seconds\"\n",
    "    )\n",
    "    if deflector_profile == \"EPL\":\n",
    "        deflector_profile = \"EPL_NUMBA\"\n",
    "    print(\n",
    "        f\"lenstronomy execution time for {deflector_profile}: {lenstronomy_execution_time} seconds\"\n",
    "    )\n",
    "    print(\n",
    "        f\"jaxtronomy is {'{0:.1f}'.format(lenstronomy_execution_time/jax_execution_time)}x faster\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing jaxtronomy and lenstronomy performance for light model surface brightness\n",
    "Note: Restarting the kernel is recommended before running the below tests on a low-memory machine, otherwise you may introduce a memory bottleneck from caching all of the compiled functions from the lens model testing in the previous cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaxtronomy execution time for CORE_SERSIC: 1.2848345000002155 seconds\n",
      "lenstronomy execution time for CORE_SERSIC: 18.967165199999727 seconds\n",
      "jaxtronomy is 14.8x faster\n",
      "\n",
      "jaxtronomy execution time for GAUSSIAN: 0.2517599999991944 seconds\n",
      "lenstronomy execution time for GAUSSIAN: 2.4892575000012584 seconds\n",
      "jaxtronomy is 9.9x faster\n",
      "\n",
      "jaxtronomy execution time for GAUSSIAN_ELLIPSE: 0.46514789999855566 seconds\n",
      "lenstronomy execution time for GAUSSIAN_ELLIPSE: 3.6453911000007793 seconds\n",
      "jaxtronomy is 7.8x faster\n",
      "\n",
      "jaxtronomy execution time for MULTI_GAUSSIAN: 0.6295931999993627 seconds\n",
      "lenstronomy execution time for MULTI_GAUSSIAN: 11.456636000000799 seconds\n",
      "jaxtronomy is 18.2x faster\n",
      "\n",
      "jaxtronomy execution time for MULTI_GAUSSIAN_ELLIPSE: 0.682676000000356 seconds\n",
      "lenstronomy execution time for MULTI_GAUSSIAN_ELLIPSE: 12.356475099999443 seconds\n",
      "jaxtronomy is 18.1x faster\n",
      "\n",
      "jaxtronomy execution time for SERSIC: 0.8067269000002852 seconds\n",
      "lenstronomy execution time for SERSIC: 8.104093699999794 seconds\n",
      "jaxtronomy is 10.0x faster\n",
      "\n",
      "jaxtronomy execution time for SERSIC_ELLIPSE: 0.8462521000001288 seconds\n",
      "lenstronomy execution time for SERSIC_ELLIPSE: 8.22898929999974 seconds\n",
      "jaxtronomy is 9.7x faster\n",
      "\n",
      "jaxtronomy execution time for SERSIC_ELLIPSE_Q_PHI: 0.8411099999993894 seconds\n",
      "lenstronomy execution time for SERSIC_ELLIPSE_Q_PHI: 8.084237500001109 seconds\n",
      "jaxtronomy is 9.6x faster\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from jax import numpy as jnp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from jaxtronomy.LightModel.light_model import LightModel\n",
    "from lenstronomy.LightModel.light_model import LightModel as LightModel_ref\n",
    "from jaxtronomy.LightModel.light_model_base import (\n",
    "    _JAXXED_MODELS as JAXXED_SOURCE_PROFILES,\n",
    ")\n",
    "\n",
    "# 60x60 grid\n",
    "num_pix = 60\n",
    "supersampling_factor = 3\n",
    "supersampling = True\n",
    "\n",
    "if supersampling:\n",
    "    num_pix *= supersampling_factor\n",
    "\n",
    "x_jax = jnp.tile(jnp.linspace(-5.0, 5.0, num_pix) + 100, num_pix)\n",
    "y_jax = jnp.repeat(jnp.linspace(-5.0, 5.0, num_pix) + 100, num_pix)\n",
    "\n",
    "x = np.tile(np.linspace(-5.0, 5.0, num_pix) + 100, num_pix)\n",
    "y = np.repeat(np.linspace(-5.0, 5.0, num_pix) + 100, num_pix)\n",
    "\n",
    "for source_profile in JAXXED_SOURCE_PROFILES:\n",
    "    lightModel = LightModel([source_profile])\n",
    "    lightModel_ref = LightModel_ref([source_profile])\n",
    "    kwargs_source = copy.deepcopy(lightModel.func_list[0].upper_limit_default)\n",
    "    for key, val in kwargs_source.items():\n",
    "        if source_profile in [\n",
    "            \"MULTI_GAUSSIAN\",\n",
    "            \"MULTI_GAUSSIAN_ELLIPSE\",\n",
    "        ] and key in [\"amp\", \"sigma\"]:\n",
    "            kwargs_source[key] = np.linspace(val / 10, val, 5)\n",
    "\n",
    "    # Do this comparison after the refactor since it is not really usable at the moment\n",
    "    if source_profile == \"SHAPELETS\":\n",
    "        continue\n",
    "        # kwargs_source[\"amp\"] = np.linspace(20.0, 30.0, 66)\n",
    "        # kwargs_source[\"n_max\"] = 10\n",
    "\n",
    "    # Compile code/warmup\n",
    "    lightModel.surface_brightness(x_jax, y_jax, [kwargs_source])\n",
    "    lightModel_ref.surface_brightness(x, y, [kwargs_source])\n",
    "\n",
    "    # Now time runtime after compilation/warmup\n",
    "    start_time = time.perf_counter()\n",
    "    for _ in range(10000):\n",
    "        lightModel.surface_brightness(x_jax, y_jax, [kwargs_source])\n",
    "\n",
    "    middle_time = time.perf_counter()\n",
    "\n",
    "    for _ in range(10000):\n",
    "        lightModel_ref.surface_brightness(x, y, [kwargs_source])\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    jax_execution_time = middle_time - start_time\n",
    "    lenstronomy_execution_time = end_time - middle_time\n",
    "    print(\n",
    "        f\"jaxtronomy execution time for {source_profile}: {jax_execution_time} seconds\"\n",
    "    )\n",
    "    print(\n",
    "        f\"lenstronomy execution time for {source_profile}: {lenstronomy_execution_time} seconds\"\n",
    "    )\n",
    "    print(\n",
    "        f\"jaxtronomy is {'{0:.1f}'.format(lenstronomy_execution_time/jax_execution_time)}x faster\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing jaxtronomy and lenstronomy performance for image convolution\n",
    "We start by comparing Gaussian convolution. Due to the fact that there is no jax.scipy.ndimage.gaussian_filter function, in jaxtronomy we implement gaussian convolution by constructing a gaussian kernel and performing a pixel kernel fft convolution. This is done in such a way to match scipy.ndimage.guassian_filter with mode=\"nearest\" as closely as possible. The jaxtronomy implementation is slower, but the benefit of this JAX implementation is that we can use autodifferentiation for model fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaxtronomy execution time for gaussian convolution with kernel radius 5: 0.5768883999990067 seconds\n",
      "lenstronomy execution time for gaussian convolution with kernel radius 5: 0.4799345999999787 seconds\n",
      "lenstronomy is 1.2x faster\n",
      "\n",
      "jaxtronomy execution time for gaussian convolution with kernel radius 9: 0.7561459000062314 seconds\n",
      "lenstronomy execution time for gaussian convolution with kernel radius 9: 0.5450878999981796 seconds\n",
      "lenstronomy is 1.4x faster\n",
      "\n",
      "jaxtronomy execution time for gaussian convolution with kernel radius 14: 1.7138018999976339 seconds\n",
      "lenstronomy execution time for gaussian convolution with kernel radius 14: 0.6546021000031033 seconds\n",
      "lenstronomy is 2.6x faster\n",
      "\n",
      "jaxtronomy execution time for gaussian convolution with kernel radius 18: 1.5250462999974843 seconds\n",
      "lenstronomy execution time for gaussian convolution with kernel radius 18: 0.7454540000035195 seconds\n",
      "lenstronomy is 2.0x faster\n",
      "\n",
      "jaxtronomy execution time for gaussian convolution with kernel radius 23: 2.2722967000008794 seconds\n",
      "lenstronomy execution time for gaussian convolution with kernel radius 23: 1.1433469999974477 seconds\n",
      "lenstronomy is 2.0x faster\n",
      "\n",
      "jaxtronomy execution time for gaussian convolution with kernel radius 27: 2.272705399998813 seconds\n",
      "lenstronomy execution time for gaussian convolution with kernel radius 27: 1.3200935999993817 seconds\n",
      "lenstronomy is 1.7x faster\n",
      "\n",
      "jaxtronomy execution time for gaussian convolution with kernel radius 32: 5.28845729999739 seconds\n",
      "lenstronomy execution time for gaussian convolution with kernel radius 32: 1.7994985000041197 seconds\n",
      "lenstronomy is 2.9x faster\n",
      "\n",
      "jaxtronomy execution time for gaussian convolution with kernel radius 36: 3.996423299999151 seconds\n",
      "lenstronomy execution time for gaussian convolution with kernel radius 36: 1.9449167999991914 seconds\n",
      "lenstronomy is 2.1x faster\n",
      "\n",
      "jaxtronomy execution time for gaussian convolution with kernel radius 41: 4.020860399999947 seconds\n",
      "lenstronomy execution time for gaussian convolution with kernel radius 41: 2.0225024000028498 seconds\n",
      "lenstronomy is 2.0x faster\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lenstronomy.ImSim.Numerics.convolution import MultiGaussianConvolution\n",
    "from jaxtronomy.ImSim.Numerics.convolution import GaussianConvolution\n",
    "\n",
    "from jax import numpy as jnp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "num_pix = 60\n",
    "sigma = 0.5\n",
    "pixel_scale = 0.11\n",
    "supersampling_factor = 3\n",
    "supersampling_convolution = False\n",
    "\n",
    "for truncation in range(1, 10):\n",
    "\n",
    "    jax_conv = GaussianConvolution(\n",
    "        sigma, pixel_scale, supersampling_factor, supersampling_convolution, truncation\n",
    "    )\n",
    "    lenstronomy_conv = MultiGaussianConvolution(\n",
    "        [sigma],\n",
    "        [1],\n",
    "        pixel_scale,\n",
    "        supersampling_factor,\n",
    "        supersampling_convolution,\n",
    "        truncation,\n",
    "    )\n",
    "\n",
    "    kernel_radius = round(sigma * truncation / pixel_scale)\n",
    "    if supersampling_convolution:\n",
    "        kernel_radius *= supersampling_factor\n",
    "\n",
    "    image_jax = jnp.tile(jnp.linspace(1.0, 100.0, num_pix), num_pix).reshape(\n",
    "        (num_pix, num_pix)\n",
    "    )\n",
    "    image = np.tile(np.linspace(1.0, 100.0, num_pix), num_pix).reshape(\n",
    "        (num_pix, num_pix)\n",
    "    )\n",
    "\n",
    "    # Compile code/warmup\n",
    "    result_jax = jax_conv.convolution2d(image_jax)\n",
    "    result = lenstronomy_conv.convolution2d(image)\n",
    "    np.testing.assert_allclose(result_jax, result, rtol=1e-5, atol=1e-5)\n",
    "\n",
    "    # Now time runtime after compilation/warmup\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    for _ in range(10000):\n",
    "        jax_conv.convolution2d(image_jax)\n",
    "\n",
    "    middle_time = time.perf_counter()\n",
    "\n",
    "    for _ in range(10000):\n",
    "        lenstronomy_conv.convolution2d(image)\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    jax_execution_time = middle_time - start_time\n",
    "    lenstronomy_execution_time = end_time - middle_time\n",
    "    print(\n",
    "        f\"jaxtronomy execution time for gaussian convolution with kernel radius {kernel_radius}: {jax_execution_time} seconds\"\n",
    "    )\n",
    "    print(\n",
    "        f\"lenstronomy execution time for gaussian convolution with kernel radius {kernel_radius}: {lenstronomy_execution_time} seconds\"\n",
    "    )\n",
    "    print(\n",
    "        f\"lenstronomy is {'{0:.1f}'.format(jax_execution_time/lenstronomy_execution_time)}x faster\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compare fft convolution with a given kernel. Generally, jax.scipy.signal.fftconvolve is about twice as fast as the normal scipy version, but there are some specific kernel sizes where the jax version is slower than usual for some unknown reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaxtronomy execution time for fft convolution with kernel size 3: 0.6867589999965276 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 3: 0.996160200003942 seconds\n",
      "jaxtronomy is 1.5x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 5: 0.3902840999944601 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 5: 0.824639999998908 seconds\n",
      "jaxtronomy is 2.1x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 7: 0.551992100001371 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 7: 0.986636699999508 seconds\n",
      "jaxtronomy is 1.8x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 9: 0.6173463000013726 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 9: 0.9937456999978167 seconds\n",
      "jaxtronomy is 1.6x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 11: 0.540529099998821 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 11: 1.0506569999997737 seconds\n",
      "jaxtronomy is 1.9x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 13: 0.5025652000040282 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 13: 0.990518599995994 seconds\n",
      "jaxtronomy is 2.0x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 15: 1.0281571999948937 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 15: 1.0750528999997186 seconds\n",
      "jaxtronomy is 1.0x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 17: 0.7497728999951505 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 17: 1.0764004000011482 seconds\n",
      "jaxtronomy is 1.4x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 19: 0.6811124000014388 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 19: 1.09988589999557 seconds\n",
      "jaxtronomy is 1.6x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 21: 0.5514467000029981 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 21: 1.2802539999975124 seconds\n",
      "jaxtronomy is 2.3x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 23: 1.280765399998927 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 23: 1.3241949000002933 seconds\n",
      "jaxtronomy is 1.0x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 25: 0.6931777999998303 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 25: 1.3736152999990736 seconds\n",
      "jaxtronomy is 2.0x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 27: 1.3640191000013147 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 27: 1.34104159999697 seconds\n",
      "jaxtronomy is 1.0x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 29: 0.7527811000036309 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 29: 1.3718086999942898 seconds\n",
      "jaxtronomy is 1.8x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 31: 0.7251101000001654 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 31: 1.3496806000039214 seconds\n",
      "jaxtronomy is 1.9x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 33: 1.0730495000025257 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 33: 1.352371699998912 seconds\n",
      "jaxtronomy is 1.3x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 35: 1.6679971999983536 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 35: 1.4206510000003618 seconds\n",
      "jaxtronomy is 0.9x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 37: 0.7758065000016359 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 37: 1.3680659999954514 seconds\n",
      "jaxtronomy is 1.8x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 39: 0.9959786999970675 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 39: 1.7799859000006109 seconds\n",
      "jaxtronomy is 1.8x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 41: 0.8213086999967345 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 41: 1.8005046000034781 seconds\n",
      "jaxtronomy is 2.2x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 43: 1.0902229999992414 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 43: 1.6611632999993162 seconds\n",
      "jaxtronomy is 1.5x faster\n",
      "\n",
      "jaxtronomy execution time for fft convolution with kernel size 45: 1.011091899999883 seconds\n",
      "lenstronomy execution time for fft convolution with kernel size 45: 1.710963300000003 seconds\n",
      "jaxtronomy is 1.7x faster\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lenstronomy.ImSim.Numerics.convolution import (\n",
    "    PixelKernelConvolution as PixelKernelConvolution_ref,\n",
    ")\n",
    "from jaxtronomy.ImSim.Numerics.convolution import PixelKernelConvolution\n",
    "\n",
    "from jax import numpy as jnp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "num_pix = 60\n",
    "supersampling_factor = 3\n",
    "supersampling_convolution = False\n",
    "if supersampling_convolution:\n",
    "    num_pix *= supersampling_factor\n",
    "\n",
    "for kernel_size in np.linspace(3, 45, 22, dtype=int):\n",
    "    kernel_jax = jnp.tile(jnp.linspace(0.1, 1.0, kernel_size), kernel_size).reshape(\n",
    "        (kernel_size, kernel_size)\n",
    "    )\n",
    "    kernel_jax = kernel_jax / jnp.sum(kernel_jax)\n",
    "    kernel = np.tile(np.linspace(0.1, 1.0, kernel_size), kernel_size).reshape(\n",
    "        (kernel_size, kernel_size)\n",
    "    )\n",
    "    kernel = kernel / np.sum(kernel)\n",
    "\n",
    "    jax_conv = PixelKernelConvolution(kernel=kernel_jax, convolution_type=\"fft\")\n",
    "    lenstronomy_conv = PixelKernelConvolution_ref(kernel=kernel, convolution_type=\"fft\")\n",
    "\n",
    "    image_jax = jnp.tile(jnp.linspace(1.0, 20.0, num_pix), num_pix).reshape(\n",
    "        (num_pix, num_pix)\n",
    "    )\n",
    "    image = np.tile(np.linspace(1.0, 20.0, num_pix), num_pix).reshape(\n",
    "        (num_pix, num_pix)\n",
    "    )\n",
    "\n",
    "    # Compile code/warmup\n",
    "    result_jax = jax_conv.convolution2d(image_jax)\n",
    "    result = lenstronomy_conv.convolution2d(image)\n",
    "    np.testing.assert_allclose(result_jax, result, rtol=1e-5, atol=1e-5)\n",
    "\n",
    "    # Now time runtime after compilation/warmup\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    for _ in range(10000):\n",
    "        jax_conv.convolution2d(image_jax)\n",
    "\n",
    "    middle_time = time.perf_counter()\n",
    "\n",
    "    for _ in range(10000):\n",
    "        lenstronomy_conv.convolution2d(image)\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    jax_execution_time = middle_time - start_time\n",
    "    lenstronomy_execution_time = end_time - middle_time\n",
    "    print(\n",
    "        f\"jaxtronomy execution time for fft convolution with kernel size {kernel_size}: {jax_execution_time} seconds\"\n",
    "    )\n",
    "    print(\n",
    "        f\"lenstronomy execution time for fft convolution with kernel size {kernel_size}: {lenstronomy_execution_time} seconds\"\n",
    "    )\n",
    "    print(\n",
    "        f\"jaxtronomy is {'{0:.1f}'.format(lenstronomy_execution_time/jax_execution_time)}x faster\\n\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
